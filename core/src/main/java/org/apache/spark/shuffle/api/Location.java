/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.shuffle.api;

import org.apache.spark.annotation.Private;

import java.io.Externalizable;
import java.io.ObjectInput;
import java.io.ObjectOutput;


/**
 * :: Private ::
 * An interface for plugging in the location of shuffle files, in order to support store shuffle
 * data in different storage, e.g., BlockManager, HDFS, S3. It would be generated by
 * {@link ShuffleMapOutputWriter} after writing a shuffle data file and used by ShuffleMapOutputReader
 * to read the shuffle data.
 *
 * Since the location is returned by {@link ShuffleMapOutputWriter#commitAllPartitions()} at executor
 * and would be sent to driver, users must ensure the location is serializable by
 *
 *  - implement a 0-arg constructor
 *  - implement {@link java.io.Externalizable#readExternal(ObjectInput)} for deserialization
 *  - implement {@link java.io.Externalizable#writeExternal(ObjectOutput)} for serialization
 *
 * Since the location will be used as keys in maps or comparing with others, users must ensure that
 * invoking {@link java.lang.Object#equals(Object)} or {@link java.lang.Object#hashCode()} on the
 * {@link Location} instances would distinguish the different locations.
 *
 * Spark has its own default implementation of {@link Location} as
 * {@link org.apache.spark.storage.BlockManagerId}, which is a subclass of {@link ExecutorLocation}
 * since each {@link org.apache.spark.storage.BlockManager} must belong to a certain executor.
 * And {@link ExecutorLocation} is a subclass of {@link HostLocation} since each executor must
 * belong to a certain host. Users should choose the appropriate location interface according to their
 * own use cases.
 *
 * @since 3.2.0
 */
@Private
public interface Location extends Externalizable {
}
